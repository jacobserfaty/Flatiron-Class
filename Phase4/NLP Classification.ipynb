{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#5642C5;\n",
    "           font-size:200%;\n",
    "           font-family:Arial;letter-spacing:0.5px\">\n",
    "\n",
    "<p width = 20%, style=\"padding: 10px;\n",
    "              color:white;\">\n",
    "Natural Language Processing: Classification\n",
    "              \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Data Science Cohort Live NYC October 2023\n",
    "<p>Phase 4</p>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<div align = \"right\">\n",
    "<img src=\"Images/flatiron-school-logo.png\" align = \"right\" width=\"200\"/>\n",
    "</div>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# integrating our preprocessing into a pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import WordNetLemmatizer # lemmatizer using WordNet\n",
    "from nltk.corpus import wordnet # imports WordNet\n",
    "from nltk import pos_tag # nltk's native part of speech tagging\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix #depreciated\n",
    "from sklearn.metrics import ConfusionMatrixDisplay,RocCurveDisplay,roc_auc_score\n",
    "#from sklearn.metrics import plot_roc_curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Build a very simple stateless transformer:\n",
    "- Cleans/preprocesses text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        #define attributes to store if text preprocessing requires fitting from data\n",
    "        pass\n",
    "    \n",
    "    def fit(self, data, y = 0):\n",
    "        # this is where you would fit things like corpus specific stopwords\n",
    "        # fit probable bigrams with bigram model in here\n",
    "        \n",
    "        # save as parameters of Text preprocessor\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, data, y = 0):\n",
    "        fully_normalized_corpus = data.apply(self.process_doc)\n",
    "        \n",
    "        return fully_normalized_corpus\n",
    "        \n",
    "    \n",
    "    def process_doc(self, doc):\n",
    "\n",
    "        #initialize lemmatizer\n",
    "        wnl = WordNetLemmatizer()\n",
    "        stop_words = stopwords.words('english')\n",
    "        \n",
    "        # helper function to change nltk's part of speech tagging to a wordnet format.\n",
    "        def pos_tagger(nltk_tag):\n",
    "            if nltk_tag.startswith('J'):\n",
    "                return wordnet.ADJ\n",
    "            elif nltk_tag.startswith('V'):\n",
    "                return wordnet.VERB\n",
    "            elif nltk_tag.startswith('N'):\n",
    "                return wordnet.NOUN\n",
    "            elif nltk_tag.startswith('R'):\n",
    "                return wordnet.ADV\n",
    "            else:         \n",
    "                return None\n",
    "\n",
    "\n",
    "        # remove stop words and punctuations, then lower case\n",
    "        doc_norm = [tok.lower() for tok in word_tokenize(doc) if ((tok.isalpha()) & (tok not in stop_words)) ]\n",
    "\n",
    "        #  POS detection on the result will be important in telling Wordnet's lemmatizer how to lemmatize\n",
    "\n",
    "        # creates list of tuples with tokens and POS tags in wordnet format\n",
    "        wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), pos_tag(doc_norm))) \n",
    "        doc_norm = [wnl.lemmatize(token, pos) for token, pos in wordnet_tagged if pos is not None]\n",
    "\n",
    "        return \" \".join(doc_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/satire_nosatire.csv')\n",
    "X = data['body']\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "proc = TextPreprocessor()\n",
    "\n",
    "transformed_train = proc.fit_transform(X_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "prc_steps = [('countvec', CountVectorizer(min_df = 0.05, max_df = 0.95))]\n",
    "preprocess_pipeline = Pipeline(prc_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_tr_proc = preprocess_pipeline.fit_transform(transformed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<700x602 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 45177 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>accord</th>\n",
       "      <th>account</th>\n",
       "      <th>accuse</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activist</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>additional</th>\n",
       "      <th>...</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>worker</th>\n",
       "      <th>world</th>\n",
       "      <th>worry</th>\n",
       "      <th>write</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 602 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     able  accord  account  accuse  act  action  activist  actually  add  \\\n",
       "0       0       0        0       1    0       0         0         0    0   \n",
       "1       0       1        0       0    0       0         0         0    1   \n",
       "2       0       0        0       0    0       0         0         0    0   \n",
       "3       0       0        0       0    0       0         0         0    0   \n",
       "4       0       0        0       1    0       0         2         0    0   \n",
       "..    ...     ...      ...     ...  ...     ...       ...       ...  ...   \n",
       "695     0       0        0       0    0       0         0         0    0   \n",
       "696     0       0        0       0    0       0         0         0    1   \n",
       "697     0       0        0       0    0       0         0         1    0   \n",
       "698     0       0        0       0    0       0         0         0    0   \n",
       "699     0       0        0       0    0       1         0         0    0   \n",
       "\n",
       "     additional  ...  word  work  worker  world  worry  write  year  yes  yet  \\\n",
       "0             0  ...     0     0       0      0      0      0     0    0    0   \n",
       "1             0  ...     0     1       0      0      0      0     1    0    0   \n",
       "2             0  ...     0     0       0      4      0      0     1    0    0   \n",
       "3             0  ...     0     2       0      0      0      1     0    0    0   \n",
       "4             0  ...     0     0       3      1      0      0     0    1    0   \n",
       "..          ...  ...   ...   ...     ...    ...    ...    ...   ...  ...  ...   \n",
       "695           0  ...     1     2       0      0      1      0     0    0    1   \n",
       "696           0  ...     0     0       0      0      0      0     1    1    0   \n",
       "697           0  ...     0     0       0      0      0      0     0    0    0   \n",
       "698           0  ...     0     0       0      0      0      0     3    0    0   \n",
       "699           0  ...     1     0       0      0      0      0     3    1    0   \n",
       "\n",
       "     young  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "695      0  \n",
       "696      0  \n",
       "697      0  \n",
       "698      0  \n",
       "699      0  \n",
       "\n",
       "[700 rows x 602 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_names = preprocess_pipeline[\n",
    "    'countvec'].get_feature_names()\n",
    "\n",
    "pd.DataFrame(X_tr_proc.toarray(), columns = feat_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Building a document classifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Naive Bayes with Multinomial Distribution Likelihood**\n",
    "\n",
    "- Can be effective for modeling document-term frequency matrix to target class relationships\n",
    "-  \"naive\" assumption that the features (term frequencies) are conditionally independent given the class label. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Bayes theorem:\n",
    "\n",
    "$$ P(c|\\textbf{x}) = \\frac{P(\\textbf{x}|c)P(c)}{P(\\textbf{x})} $$\n",
    "\n",
    "- Likelihood; $P(\\textbf{x}|c)$\n",
    "- Prior: $P(c)$\n",
    "- Posterior: $P(c|\\textbf{x}) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Bayes classifier:\n",
    "    \n",
    "$$f(\\textbf{x}) = \\hat{c} = \\underset{c \\in C}{\\arg\\max} P(\\textbf{x}|c)P(c)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Prior\n",
    "- simply the target fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_priors = y_train.value_counts()/y_train.shape[0]\n",
    "class_priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The likelihood function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**First step: word count distribution**:\n",
    "\n",
    "- Multinomial distribution (generalization of \n",
    "binomial distribution)\n",
    "\n",
    "For document with $m$ tokens:\n",
    "- dictionary of corpus has $d$ unique tokens.\n",
    "- $\\textbf{x} = (x_1,...., x_d)$ vector of token counts for document.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "An analogy: $d = 6$ M&M colors\n",
    "\n",
    "Picking $ m $ M&Ms.\n",
    "\n",
    "<img src = \"Images/picking_candy.jpg\" >\n",
    "    \n",
    "Follow multinomial distribution.\n",
    "\n",
    "\n",
    "<a href = \"https://www.mashed.com/679227/the-rarest-mm-color-may-surprise-you/#:~:text=Brown%20is%20currently%20the%20rarest%20color%20of%20M%26M's&text=As%20such%2C%20they%20used%20their,their%20findings%20were%20quite%20surprising.\"> Some interesting facts about M&Ms. </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$ P(\\textbf{x}|\\theta) = \\frac{m!}{x_1!x_2!...x_d!} \\theta_{1}^{x_1}\\theta_{2}^{x_2}...\\theta_{d}^{x_d} $$\n",
    "Parameters of distribution:\n",
    "- $\\theta_i$: probability of picking $i^{th}$ token  in dictionary from bag of words\n",
    "\n",
    "**To be estimated from the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Words draws/order are **independent** of each other: the **naive** assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/scrabble.webp\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Second Step: class conditional word count\n",
    "\n",
    "$$ P(\\textbf{x}|c) = \\frac{m!}{x_1!x_2!...x_d!} [\\theta_c]_{1}^{x_1}[\\theta_c]_{2}^{x_2}...[\\theta_c]_{d}^{x_d} $$\n",
    "- $[\\theta_c]$ is **class-dependent** set of probability parameters.\n",
    "\n",
    "Need to fit probability parameters from data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Fitting probability parameters for each class**\n",
    "\n",
    "- Very straightforward.\n",
    "- Probability of drawing token $i$ if document class $c$\n",
    "\n",
    "$$ [\\hat{\\theta}_c]_i = \\frac{N_{ci}}{N_c}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Count token $i$ occurence across all documents of class $c$\n",
    "- Divide by total token count for all documents of class $c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Getting the fit parameters with code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>accord</th>\n",
       "      <th>account</th>\n",
       "      <th>accuse</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activist</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>additional</th>\n",
       "      <th>...</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>worker</th>\n",
       "      <th>world</th>\n",
       "      <th>worry</th>\n",
       "      <th>write</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 602 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     able  accord  account  accuse  act  action  activist  actually  add  \\\n",
       "0       0       0        0       1    0       0         0         0    0   \n",
       "1       0       1        0       0    0       0         0         0    1   \n",
       "2       0       0        0       0    0       0         0         0    0   \n",
       "3       0       0        0       0    0       0         0         0    0   \n",
       "4       0       0        0       1    0       0         2         0    0   \n",
       "..    ...     ...      ...     ...  ...     ...       ...       ...  ...   \n",
       "695     0       0        0       0    0       0         0         0    0   \n",
       "696     0       0        0       0    0       0         0         0    1   \n",
       "697     0       0        0       0    0       0         0         1    0   \n",
       "698     0       0        0       0    0       0         0         0    0   \n",
       "699     0       0        0       0    0       1         0         0    0   \n",
       "\n",
       "     additional  ...  word  work  worker  world  worry  write  year  yes  yet  \\\n",
       "0             0  ...     0     0       0      0      0      0     0    0    0   \n",
       "1             0  ...     0     1       0      0      0      0     1    0    0   \n",
       "2             0  ...     0     0       0      4      0      0     1    0    0   \n",
       "3             0  ...     0     2       0      0      0      1     0    0    0   \n",
       "4             0  ...     0     0       3      1      0      0     0    1    0   \n",
       "..          ...  ...   ...   ...     ...    ...    ...    ...   ...  ...  ...   \n",
       "695           0  ...     1     2       0      0      1      0     0    0    1   \n",
       "696           0  ...     0     0       0      0      0      0     1    1    0   \n",
       "697           0  ...     0     0       0      0      0      0     0    0    0   \n",
       "698           0  ...     0     0       0      0      0      0     3    0    0   \n",
       "699           0  ...     1     0       0      0      0      0     3    1    0   \n",
       "\n",
       "     young  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "695      0  \n",
       "696      0  \n",
       "697      0  \n",
       "698      0  \n",
       "699      0  \n",
       "\n",
       "[700 rows x 602 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_mat = pd.DataFrame(X_tr_proc.toarray(), columns = feat_names)\n",
    "bow_mat['target'] = y_train\n",
    "bow_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "say       0.033241\n",
       "people    0.009515\n",
       "year      0.009304\n",
       "see       0.007588\n",
       "take      0.007527\n",
       "state     0.007437\n",
       "eu        0.007256\n",
       "go        0.006865\n",
       "get       0.006714\n",
       "make      0.006534\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class1_bow_mat = bow_mat[bow_mat['target'] == 1].drop(columns = ['target'])\n",
    "\n",
    "# class 1 token probabilities:\n",
    "N_tok_1 = class1_bow_mat.sum(axis = 0) # token occurence\n",
    "N_1 =  class1_bow_mat.values.sum() # number of tokens\n",
    "\n",
    "# get probabilities for each token: class 1\n",
    "proba_c1 = N_tok_1/N_1\n",
    "\n",
    "proba_c1.sort_values(ascending = False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "say           0.032553\n",
       "year          0.012070\n",
       "people        0.011485\n",
       "trump         0.010388\n",
       "state         0.008266\n",
       "government    0.007901\n",
       "president     0.007315\n",
       "get           0.006876\n",
       "time          0.006803\n",
       "take          0.006730\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class0_bow_mat = bow_mat[bow_mat['target'] == 0].drop(columns = ['target'])\n",
    "\n",
    "# class 1 token probabilities:\n",
    "N_tok_0 = class0_bow_mat.sum(axis = 0)\n",
    "N_0 =  class0_bow_mat.values.sum() \n",
    "\n",
    "# get probabilities for each token: class 0\n",
    "proba_c0 = N_tok_0/N_0\n",
    "\n",
    "proba_c0.sort_values(ascending = False)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Computing likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Take document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Speaking from his bunker deep in the Treasury, the Remoaner, Lord Haw Haw Hammond broadcasted that he is delighted with the punishment budget he will unleash across the whole of Britain. The Voice of the Axis “In line with my Remainer policies, and the vile impudent populace who voted for Brexit, I wish to punish you deeply by raising taxes and taking away funding from key areas of the economy. It’s because you people <spitting> still do not capitulate to our masters in Brussels. I was planted into this high position by our Remainer Prime Minister, Theresa May, and the Remainer led Cabinet. I am justified in punishing you British swine for your indiscretions. Haw, haw, haw, haw!” Many Brits who are already struggling under the regime of a Remainer-led Cabinet were naturally defiant about Lord Haw Haw Hammond’s punishment budget. “They can punish us as much as they want. They can have as many referendums as they want, we will not surrender, we will fight from the hill tops, we will fight from the beaches, we will fight from the city centres, we will fight from the Tesco car parks, we will never surrender to Brussels or to Lord Haw Haw Hammond and his vindictive spiteful taunts,” Reggie Churchill, 35, from Kent told local news services.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "able       0\n",
       "accord     0\n",
       "account    0\n",
       "accuse     0\n",
       "act        0\n",
       "          ..\n",
       "write      0\n",
       "year       0\n",
       "yes        0\n",
       "yet        0\n",
       "young      0\n",
       "Name: 50, Length: 601, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bow vector for document\n",
    "bow_mat_feat = bow_mat.drop(columns = ['target'])\n",
    "word_vec = bow_mat_feat.iloc[50]\n",
    "word_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is satire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.iloc[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_length = word_vec.sum()\n",
    "article_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class1_likelihood = multinomial.pmf(x = word_vec.values, n = article_length, p =  proba_c1.values)\n",
    "class0_likelihood = multinomial.pmf(x = word_vec.values, n = article_length, p =  proba_c0.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now use Bayes theorem for classifier:\n",
    "\n",
    "$$f(\\textbf{x}) = \\hat{c} = \\underset{c \\in C}{\\arg\\max} P(\\textbf{x}|c)P(c)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "with multinomial likelihood\n",
    "\n",
    "$$ P(\\textbf{x}|c) = \\frac{m!}{x_1!x_2!...x_d!} [\\hat{\\theta}_c]_{1}^{x_1}[\\hat{\\theta}_c]_{2}^{x_2}...[\\hat{\\theta}_c]_{d}^{x_d} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "and fitted parameters\n",
    "\n",
    "$$ [\\hat{\\theta}_c]_i = \\frac{N_{ci}}{N_c}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Evaluate class for this document:\n",
    "\n",
    "$$f(\\textbf{x}) = \\hat{c} = \\underset{c \\in C}{\\arg\\max} P(\\textbf{x}|c)P(c)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6065138126391637e-74"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class1_likelihood*class_priors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.402394829433637e-79"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class0_likelihood*class_priors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Given scale of probabilities:\n",
    "- Comparison done on log scale\n",
    "\n",
    "$$f(\\textbf{x}) = \\hat{c} = \\underset{c \\in C}{\\arg\\max} \\Big[ \\log\\Big(P(\\textbf{x}|c)P(c)\\Big) \\Big]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-73.7941155360775"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log10(class1_likelihood*class_priors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-78.19365754684966"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log10(class0_likelihood*class_priors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Laplace Smoothing: practical correction\n",
    "\n",
    "- A fudge count $\\alpha$ added to token count in each class.\n",
    "- Avoids issues with having zero counts $N_c$ and $N_{ci}$ in training set.\n",
    "\n",
    "$$ [\\hat{\\theta}_c]_i = \\frac{N_{ci} + \\alpha}{N_c + \\alpha d}$$\n",
    "\n",
    "- Typically $\\alpha = 1$. Can tune this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "- $d$ is the dimensionality of our vocabulary\n",
    "- $N_{ci}$ the count of token $i$ in class $c$\n",
    "- $N_{c}$ the count of all tokens in class $c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Append Multinomial Naive Bayes Classifier to pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('countvec', CountVectorizer(max_df=0.95, min_df=0.05)),\n",
       " ('multinb', MultinomialNB())]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "mod_pipe = deepcopy(preprocess_pipeline)\n",
    "mod_pipe.steps.append(('multinb', MultinomialNB()))\n",
    "mod_pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvec', CountVectorizer(max_df=0.95, min_df=0.05)),\n",
       "                ('multinb', MultinomialNB())])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_pipe.fit(transformed_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "transformed_test = proc.transform(X_test)\n",
    "\n",
    "y_pred = mod_pipe.predict(transformed_test) # automatically applies vectorizer and predicts on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       150\n",
      "           1       0.97      0.95      0.96       150\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.96      0.96      0.96       300\n",
      "weighted avg       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9633333333333334"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'RocCurveDisplay' has no attribute 'from_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ff0b0a7abfdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#plot_roc_curve(mod_pipe, transformed_test, y_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mRocCurveDisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_pipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'RocCurveDisplay' has no attribute 'from_estimator'"
     ]
    }
   ],
   "source": [
    "#plot_roc_curve(mod_pipe, transformed_test, y_test)\n",
    "RocCurveDisplay.from_estimator(mod_pipe, transformed_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#plot_confusion_matrix(mod_pipe, transformed_test, y_test);\n",
    "ConfusionMatrixDisplay.from_estimator(mod_pipe, transformed_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- with proper text preprocessing steps\n",
    "- Naive Bayes can perform really well on simple binary classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Using TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "TFIDF does not necessarily perform better than CV:\n",
    "- It is just a tool in our toolbelt often worth trying out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tfidf', TfidfVectorizer(max_df=0.95, min_df=0.05)),\n",
       " ('multinb', MultinomialNB())]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "tfidfmod_pipe = deepcopy(mod_pipe)\n",
    "tfidfmod_pipe.steps[0] = ('tfidf', TfidfVectorizer(min_df=0.05, max_df=0.95)) # cuts words too rare/too frequent\n",
    "tfidfmod_pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tfidfmod_pipe.fit(transformed_train, y_train)\n",
    "ypred_tfidf = tfidfmod_pipe.predict(transformed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9566666666666667"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, ypred_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(tfidfmod_pipe, transformed_test, y_test);\n",
    "# ConfusionMatrixDisplay.from_estimator(tfidfmod_pipe, transformed_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### With class imbalance\n",
    "\n",
    "- Modification to Multinomial Naive Bayes: Complement Naive Bayes\n",
    "- deals with data skew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pretty much same fitting/hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('countvec', CountVectorizer(max_df=0.95, min_df=0.05)),\n",
       " ('compnb', ComplementNB())]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "mod_comp_pipe = deepcopy(preprocess_pipeline)\n",
    "mod_comp_pipe.steps.append(('compnb', ComplementNB()))\n",
    "mod_comp_pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvec', CountVectorizer(max_df=0.95, min_df=0.05)),\n",
       "                ('compnb', ComplementNB())])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_comp_pipe.fit(transformed_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_test = proc.transform(X_test) #preprocess\n",
    "y_pred_comp = mod_comp_pipe.predict(transformed_test) #count vectorizer and ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       153\n",
      "           1       0.95      0.97      0.96       147\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.96      0.96      0.96       300\n",
      "weighted avg       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred_comp, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(mod_comp_pipe, transformed_test, y_test);\n",
    "# ConfusionMatrixDisplay.from_estimator(mod_comp_pipe, transformed_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Comparable performance on this balanced dataset. Will perform *much* better on imbalanced dataset than MultinomialNB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
